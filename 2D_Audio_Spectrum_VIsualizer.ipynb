{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 🎵 **A complete Python code snippet for creating an audio spectrum visualizer in Google Colab by Worachat W., Ph.D. 2025** 🎵  \n",
        "\n",
        "This visualizer allows you to upload a WAV audio file and displays a bar-based frequency spectrum that updates in real-time as the audio plays. It uses Matplotlib for visualization and IPython for audio playback.\n",
        "\n",
        "---\n",
        "\n",
        "## Audio Spectrum Visualizer in Google Colab\n",
        "\n",
        "### Overview\n",
        "This code:\n",
        "1. Uploads an audio file (WAV format) using Google Colab's file upload feature.\n",
        "2. Processes the audio to compute its frequency spectrum using the Fast Fourier Transform (FFT).\n",
        "3. Creates an animated bar plot to visualize the spectrum.\n",
        "4. Provides an audio player to listen to the file while watching the visualization.\n",
        "\n",
        "### Prerequisites\n",
        "- Run this code in a Google Colab notebook.\n",
        "- Ensure your audio file is in WAV format (e.g., `sample.wav`).\n",
        "\n",
        "---\n",
        "\n",
        "### How to Use\n",
        "1. **Copy the Code**: Paste this code into a cell in a Google Colab notebook.\n",
        "2. **Run the Cell**: Execute the cell by pressing `Shift + Enter`.\n",
        "3. **Upload a File**: A file upload prompt will appear. Upload a WAV audio file from your computer.\n",
        "4. **View the Output**:\n",
        "   - An animated bar plot will appear, showing the frequency spectrum.\n",
        "   - An audio player will display below the animation. Click \"Play\" to listen to the audio while watching the visualization.\n",
        "\n",
        "### Explanation\n",
        "- **File Upload**: Uses `files.upload()` to let you upload a WAV file.\n",
        "- **Audio Processing**: The `wave` library reads the file, and the data is converted to a NumPy array. Stereo audio is simplified to mono by taking the first channel.\n",
        "- **STFT**: The audio is split into overlapping windows (1024 samples each, shifted by 512 samples). The FFT is computed for each window to get the frequency spectrum.\n",
        "- **Visualization**: A bar plot with 64 bars (representing the first 64 frequency bins) updates dynamically using `FuncAnimation`. Each bar’s height reflects the magnitude of a frequency bin.\n",
        "- **Audio Playback**: `IPython.display.Audio` creates a playable audio widget with the processed audio data.\n",
        "\n",
        "### Notes\n",
        "- **Supported Format**: This code works with WAV files. For other formats (e.g., MP3), you’d need a library like `librosa` (install with `!pip install librosa` and modify the code).\n",
        "- **Y-Axis Scaling**: The `ax.set_ylim(0, 10000)` is a fixed limit. If the bars are too small or clipped, adjust this value based on your audio’s volume.\n",
        "- **Performance**: For long audio files, animation generation may take time. Use a short clip (e.g., 10-20 seconds) for best results.\n",
        "- **Synchronization**: The animation and audio aren’t perfectly synced but are close enough for a visual effect. Start the audio manually after the animation appears.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "EqjBBKVjixkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "!pip install pydub\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from google.colab import files\n",
        "import io\n",
        "import wave\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "# Step 1: Upload the audio file\n",
        "print(\"Please upload a WAV audio file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Access the uploaded file\n",
        "for filename in uploaded.keys():\n",
        "    audio_data = uploaded[filename]\n",
        "    audio_file = io.BytesIO(audio_data)\n",
        "\n",
        "# Step 2: Read the audio file\n",
        "with wave.open(audio_file, 'rb') as wf:\n",
        "    sample_rate = wf.getframerate()  # e.g., 44100 Hz\n",
        "    n_channels = wf.getnchannels()   # 1 for mono, 2 for stereo\n",
        "    sample_width = wf.getsampwidth() # 1 for 8-bit, 2 for 16-bit\n",
        "    n_frames = wf.getnframes()       # Total number of frames\n",
        "    audio_data = wf.readframes(n_frames)  # Raw audio bytes\n",
        "\n",
        "# Step 3: Convert audio data to NumPy array\n",
        "if sample_width == 2:\n",
        "    audio_np = np.frombuffer(audio_data, dtype=np.int16)\n",
        "elif sample_width == 1:\n",
        "    audio_np = np.frombuffer(audio_data, dtype=np.uint8) - 128  # Convert to signed\n",
        "else:\n",
        "    raise ValueError(\"Unsupported sample width\")\n",
        "\n",
        "# If stereo, use the first channel only\n",
        "if n_channels > 1:\n",
        "    audio_np = audio_np.reshape(-1, n_channels)[:, 0]\n",
        "\n",
        "# Step 4: Define parameters for Short-Time Fourier Transform (STFT)\n",
        "window_size = 1024  # Number of samples per FFT window\n",
        "hop_size = 512     # Number of samples between successive windows\n",
        "n_bins = 64        # Number of frequency bins to display\n",
        "n_frames = int(np.floor((len(audio_np) - window_size) / hop_size)) + 1  # Total frames\n",
        "\n",
        "# Step 5: Set up the visualization plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.set_facecolor('black')          # Black background\n",
        "ax.set_ylim(0, 10000)              # Y-axis limit (adjust if needed)\n",
        "ax.set_xlim(-0.5, n_bins - 0.5)    # X-axis limit for 64 bars\n",
        "ax.axis('off')                     # Hide axes\n",
        "bars = ax.bar(range(n_bins), np.zeros(n_bins), color='green', width=0.8)  # Create bars\n",
        "\n",
        "# Step 6: Define the animation update function\n",
        "def update(frame):\n",
        "    start = frame * hop_size\n",
        "    if start + window_size > len(audio_np):\n",
        "        return bars  # Stop if window exceeds audio length\n",
        "    # Extract window and apply Hamming window\n",
        "    windowed_data = audio_np[start:start + window_size] * np.hamming(window_size)\n",
        "    # Compute FFT and get magnitudes\n",
        "    fft_data = np.fft.fft(windowed_data, n=window_size)\n",
        "    magnitudes = np.abs(fft_data[:n_bins])\n",
        "    # Update bar heights\n",
        "    for bar, height in zip(bars, magnitudes):\n",
        "        bar.set_height(height)\n",
        "    return bars\n",
        "\n",
        "# Step 7: Create the animation\n",
        "interval = (hop_size / sample_rate) * 1000  # Frame interval in milliseconds\n",
        "ani = FuncAnimation(fig, update, frames=n_frames, interval=interval, blit=False)\n",
        "\n",
        "# Step 8: Display the animation\n",
        "display(HTML(ani.to_jshtml()))\n",
        "\n",
        "# Step 9: Display the audio player\n",
        "display(Audio(audio_np, rate=sample_rate))"
      ],
      "metadata": {
        "id": "WZ-f07D5gfYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ This code has been modified to include **both a real-time waveform and spectrogram display** using `matplotlib.animation`.\n",
        "\n",
        "**Key updates:**\n",
        "\n",
        "* A subplot layout was added to show **two graphs**: a waveform (top) and a spectrogram (bottom).\n",
        "* FFT data is visualized as a growing spectrogram (`imshow`) that updates in real-time.\n",
        "* The waveform scrolls with each audio window."
      ],
      "metadata": {
        "id": "eENp_zAXpqBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "!pip install pydub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from google.colab import files\n",
        "import io\n",
        "import wave\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "# Step 1: Upload the audio file\n",
        "print(\"Please upload a WAV audio file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Access the uploaded file\n",
        "for filename in uploaded.keys():\n",
        "    audio_data = uploaded[filename]\n",
        "    audio_file = io.BytesIO(audio_data)\n",
        "\n",
        "# Step 2: Read the audio file\n",
        "with wave.open(audio_file, 'rb') as wf:\n",
        "    sample_rate = wf.getframerate()\n",
        "    n_channels = wf.getnchannels()\n",
        "    sample_width = wf.getsampwidth()\n",
        "    n_frames = wf.getnframes()\n",
        "    audio_data = wf.readframes(n_frames)\n",
        "\n",
        "# Step 3: Convert audio data to NumPy array\n",
        "if sample_width == 2:\n",
        "    audio_np = np.frombuffer(audio_data, dtype=np.int16)\n",
        "elif sample_width == 1:\n",
        "    audio_np = np.frombuffer(audio_data, dtype=np.uint8) - 128\n",
        "else:\n",
        "    raise ValueError(\"Unsupported sample width\")\n",
        "\n",
        "if n_channels > 1:\n",
        "    audio_np = audio_np.reshape(-1, n_channels)[:, 0]\n",
        "\n",
        "# Step 4: Define parameters\n",
        "window_size = 1024\n",
        "hop_size = 512\n",
        "n_bins = 512\n",
        "n_frames = int(np.floor((len(audio_np) - window_size) / hop_size)) + 1\n",
        "\n",
        "# Step 5: Set up plots for both waveform and spectrogram\n",
        "fig, (ax_wave, ax_spec) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "# Waveform setup\n",
        "ax_wave.set_title(\"Real-Time Waveform\")\n",
        "ax_wave.set_xlim(0, window_size)\n",
        "ax_wave.set_ylim(-2**15, 2**15)\n",
        "line_wave, = ax_wave.plot(np.zeros(window_size), color='cyan')\n",
        "\n",
        "# Spectrogram setup\n",
        "ax_spec.set_title(\"Real-Time Spectrogram\")\n",
        "ax_spec.set_facecolor('black')\n",
        "spec_img = ax_spec.imshow(np.zeros((n_bins, 1)), aspect='auto', origin='lower',\n",
        "                          extent=[0, 1, 0, sample_rate/2], cmap='magma')\n",
        "\n",
        "# Step 6: Define animation update function\n",
        "def update(frame):\n",
        "    start = frame * hop_size\n",
        "    if start + window_size > len(audio_np):\n",
        "        return line_wave, spec_img\n",
        "\n",
        "    # Extract current audio frame\n",
        "    frame_data = audio_np[start:start + window_size]\n",
        "\n",
        "    # Update waveform\n",
        "    line_wave.set_ydata(frame_data)\n",
        "\n",
        "    # Apply window and compute FFT\n",
        "    windowed = frame_data * np.hamming(window_size)\n",
        "    fft_data = np.abs(np.fft.rfft(windowed))\n",
        "    fft_data = fft_data[:n_bins].reshape(-1, 1)\n",
        "\n",
        "    # Update spectrogram\n",
        "    current_spec = spec_img.get_array()\n",
        "    updated_spec = np.hstack((current_spec, fft_data))\n",
        "    spec_img.set_array(updated_spec)\n",
        "    spec_img.set_extent([0, updated_spec.shape[1], 0, sample_rate/2])\n",
        "\n",
        "    return line_wave, spec_img\n",
        "\n",
        "# Step 7: Create the animation\n",
        "interval = (hop_size / sample_rate) * 1000\n",
        "ani = FuncAnimation(fig, update, frames=n_frames, interval=interval, blit=False)\n",
        "\n",
        "# Step 8: Display animation and audio\n",
        "plt.tight_layout()\n",
        "display(HTML(ani.to_jshtml()))\n",
        "display(Audio(audio_np, rate=sample_rate))"
      ],
      "metadata": {
        "id": "9YgusUahmVPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎵 **An improved version of your audio visualization code that's optimized for Google Colab with better UI elements, error handling, and user experience.**🎵  \n",
        "\n",
        "It has significantly enhanced your audio visualization code for Google Colab with the following improvements:\n",
        "\n",
        "## 🚀 **Key Enhancements:**\n",
        "\n",
        "### **1. Better File Support**\n",
        "- Uses `librosa` for loading multiple audio formats (MP3, FLAC, M4A, OGG, etc.)\n",
        "- Fallback to `wave` module for WAV files\n",
        "- Improved error handling and user feedback\n",
        "\n",
        "### **2. Interactive UI Controls**\n",
        "- **Window Size & Hop Size sliders** for real-time parameter adjustment\n",
        "- **Colormap selector** with multiple visualization styles\n",
        "- **Speed control** to adjust playback speed (0.1x to 5x)\n",
        "- **Play/Stop buttons** for better control\n",
        "\n",
        "### **3. Enhanced Visualizations**\n",
        "- **Dark theme** optimized for Colab\n",
        "- **Gradient waveform** with better styling\n",
        "- **dB-scale spectrogram** with colorbar\n",
        "- **Progress indicator** in the title\n",
        "- **Grid lines and labels** for better readability\n",
        "\n",
        "### **4. User Experience**\n",
        "- **Clear status messages** with emojis for better feedback\n",
        "- **Organized workflow** with step-by-step guidance\n",
        "- **Professional styling** with proper layouts\n",
        "- **Audio normalization** to prevent clipping\n",
        "\n",
        "### **5. Technical Improvements**\n",
        "- **Object-oriented design** for better code organization\n",
        "- **Memory management** with limited spectrogram history\n",
        "- **Error handling** at multiple levels\n",
        "- **Widget integration** for interactive controls\n",
        "\n",
        "## 🎯 **Usage:**\n",
        "1. Run the code in Google Colab\n",
        "2. Upload your audio file when prompted\n",
        "3. Adjust the visualization parameters using the sliders\n",
        "4. Click \"Start Visualization\" to begin\n",
        "5. Use the audio player to listen along\n",
        "\n",
        "The enhanced version provides a much more professional and user-friendly experience while maintaining all the original functionality!"
      ],
      "metadata": {
        "id": "GOGZwStnCkuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Audio Visualizer for Google Colab\n",
        "# Install required packages\n",
        "!pip install pydub librosa -q\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from matplotlib.widgets import Button\n",
        "from google.colab import files\n",
        "import io\n",
        "import wave\n",
        "import librosa\n",
        "from IPython.display import Audio, display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, FloatSlider, IntSlider, Dropdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class AudioVisualizer:\n",
        "    def __init__(self):\n",
        "        self.audio_np = None\n",
        "        self.sample_rate = None\n",
        "        self.filename = None\n",
        "        self.animation = None\n",
        "        self.fig = None\n",
        "        self.is_playing = False\n",
        "\n",
        "    def upload_and_process_audio(self):\n",
        "        \"\"\"Enhanced audio upload with better file support and error handling\"\"\"\n",
        "        print(\"🎵 Audio Visualizer - Enhanced for Google Colab\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"📁 Please upload an audio file (WAV, MP3, FLAC, etc.)\")\n",
        "        print(\"   Supported formats: WAV, MP3, FLAC, M4A, OGG\")\n",
        "\n",
        "        try:\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            if not uploaded:\n",
        "                print(\"❌ No file uploaded. Please try again.\")\n",
        "                return False\n",
        "\n",
        "            # Process the uploaded file\n",
        "            for filename in uploaded.keys():\n",
        "                self.filename = filename\n",
        "                print(f\"📄 Processing: {filename}\")\n",
        "\n",
        "                # Use librosa for better format support\n",
        "                audio_data = uploaded[filename]\n",
        "\n",
        "                # Load audio with librosa (supports many formats)\n",
        "                try:\n",
        "                    self.audio_np, self.sample_rate = librosa.load(\n",
        "                        io.BytesIO(audio_data),\n",
        "                        sr=None,  # Keep original sample rate\n",
        "                        mono=True  # Convert to mono\n",
        "                    )\n",
        "\n",
        "                    # Normalize audio to prevent clipping\n",
        "                    if self.audio_np.max() > 1.0:\n",
        "                        self.audio_np = self.audio_np / np.max(np.abs(self.audio_np))\n",
        "\n",
        "                    # Convert to int16 for visualization\n",
        "                    self.audio_np = (self.audio_np * 32767).astype(np.int16)\n",
        "\n",
        "                    duration = len(self.audio_np) / self.sample_rate\n",
        "\n",
        "                    print(f\"✅ Successfully loaded!\")\n",
        "                    print(f\"   📊 Sample Rate: {self.sample_rate} Hz\")\n",
        "                    print(f\"   ⏱️  Duration: {duration:.2f} seconds\")\n",
        "                    print(f\"   📏 Samples: {len(self.audio_np):,}\")\n",
        "\n",
        "                    return True\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error loading audio with librosa: {e}\")\n",
        "                    # Fallback to wave module for WAV files\n",
        "                    return self._load_with_wave(io.BytesIO(audio_data))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Upload failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _load_with_wave(self, audio_file):\n",
        "        \"\"\"Fallback method using wave module\"\"\"\n",
        "        try:\n",
        "            with wave.open(audio_file, 'rb') as wf:\n",
        "                self.sample_rate = wf.getframerate()\n",
        "                n_channels = wf.getnchannels()\n",
        "                sample_width = wf.getsampwidth()\n",
        "                n_frames = wf.getnframes()\n",
        "                audio_data = wf.readframes(n_frames)\n",
        "\n",
        "            if sample_width == 2:\n",
        "                self.audio_np = np.frombuffer(audio_data, dtype=np.int16)\n",
        "            elif sample_width == 1:\n",
        "                self.audio_np = np.frombuffer(audio_data, dtype=np.uint8) - 128\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported sample width: {sample_width}\")\n",
        "\n",
        "            if n_channels > 1:\n",
        "                self.audio_np = self.audio_np.reshape(-1, n_channels)[:, 0]\n",
        "\n",
        "            print(\"✅ Loaded with wave module (WAV format)\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load audio: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_interactive_controls(self):\n",
        "        \"\"\"Create interactive widgets for customization\"\"\"\n",
        "        print(\"\\n🎛️ Visualization Controls\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Create interactive widgets\n",
        "        self.window_size_widget = IntSlider(\n",
        "            value=1024, min=256, max=4096, step=256,\n",
        "            description='Window Size:', style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.hop_size_widget = IntSlider(\n",
        "            value=512, min=128, max=2048, step=128,\n",
        "            description='Hop Size:', style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.colormap_widget = Dropdown(\n",
        "            options=['magma', 'viridis', 'plasma', 'inferno', 'hot', 'cool', 'spring'],\n",
        "            value='magma', description='Colormap:', style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.speed_widget = FloatSlider(\n",
        "            value=1.0, min=0.1, max=5.0, step=0.1,\n",
        "            description='Speed:', style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # Display widgets\n",
        "        display(widgets.HBox([self.window_size_widget, self.hop_size_widget]))\n",
        "        display(widgets.HBox([self.colormap_widget, self.speed_widget]))\n",
        "\n",
        "        # Add buttons\n",
        "        self.play_button = widgets.Button(\n",
        "            description=\"🎬 Start Visualization\",\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='200px', height='40px')\n",
        "        )\n",
        "\n",
        "        self.stop_button = widgets.Button(\n",
        "            description=\"⏹️ Stop\",\n",
        "            button_style='danger',\n",
        "            layout=widgets.Layout(width='100px', height='40px')\n",
        "        )\n",
        "\n",
        "        self.play_button.on_click(self._on_play_click)\n",
        "        self.stop_button.on_click(self._on_stop_click)\n",
        "\n",
        "        display(widgets.HBox([self.play_button, self.stop_button]))\n",
        "\n",
        "    def _on_play_click(self, button):\n",
        "        \"\"\"Handle play button click\"\"\"\n",
        "        if not self.is_playing:\n",
        "            self.create_visualization()\n",
        "            self.is_playing = True\n",
        "            self.play_button.description = \"🔄 Restart\"\n",
        "            self.play_button.button_style = 'warning'\n",
        "\n",
        "    def _on_stop_click(self, button):\n",
        "        \"\"\"Handle stop button click\"\"\"\n",
        "        if self.animation:\n",
        "            self.animation.event_source.stop()\n",
        "        if self.fig:\n",
        "            plt.close(self.fig)\n",
        "        self.is_playing = False\n",
        "        self.play_button.description = \"🎬 Start Visualization\"\n",
        "        self.play_button.button_style = 'success'\n",
        "        clear_output(wait=True)\n",
        "        print(\"⏹️ Visualization stopped\")\n",
        "\n",
        "    def create_visualization(self):\n",
        "        \"\"\"Create the enhanced visualization\"\"\"\n",
        "        if self.audio_np is None:\n",
        "            print(\"❌ No audio loaded. Please upload a file first.\")\n",
        "            return\n",
        "\n",
        "        # Get parameters from widgets\n",
        "        window_size = self.window_size_widget.value\n",
        "        hop_size = self.hop_size_widget.value\n",
        "        colormap = self.colormap_widget.value\n",
        "        speed_multiplier = self.speed_widget.value\n",
        "\n",
        "        n_bins = window_size // 2\n",
        "        n_frames = int(np.floor((len(self.audio_np) - window_size) / hop_size)) + 1\n",
        "\n",
        "        print(f\"\\n🎨 Creating visualization...\")\n",
        "        print(f\"   🖼️  Window Size: {window_size}\")\n",
        "        print(f\"   👣 Hop Size: {hop_size}\")\n",
        "        print(f\"   🎨 Colormap: {colormap}\")\n",
        "        print(f\"   ⚡ Speed: {speed_multiplier}x\")\n",
        "\n",
        "        # Set up the figure with better styling\n",
        "        plt.style.use('dark_background')\n",
        "        self.fig, (ax_wave, ax_spec) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "        self.fig.patch.set_facecolor('black')\n",
        "\n",
        "        # Enhanced waveform setup\n",
        "        ax_wave.set_title(f\"🌊 Real-Time Waveform - {self.filename}\",\n",
        "                         fontsize=14, color='white', pad=20)\n",
        "        ax_wave.set_xlim(0, window_size)\n",
        "        ax_wave.set_ylim(-32768, 32767)\n",
        "        ax_wave.set_xlabel('Samples', color='white')\n",
        "        ax_wave.set_ylabel('Amplitude', color='white')\n",
        "        ax_wave.grid(True, alpha=0.3)\n",
        "        ax_wave.set_facecolor('#0a0a0a')\n",
        "\n",
        "        # Create gradient line for waveform\n",
        "        line_wave, = ax_wave.plot(np.zeros(window_size), color='cyan',\n",
        "                                 linewidth=1.5, alpha=0.8)\n",
        "\n",
        "        # Enhanced spectrogram setup\n",
        "        ax_spec.set_title(\"🌈 Real-Time Spectrogram\", fontsize=14, color='white', pad=20)\n",
        "        ax_spec.set_facecolor('black')\n",
        "        ax_spec.set_xlabel('Time Frames', color='white')\n",
        "        ax_spec.set_ylabel('Frequency (Hz)', color='white')\n",
        "\n",
        "        # Initialize spectrogram\n",
        "        spec_data = np.zeros((n_bins, 100))  # Start with some width\n",
        "        spec_img = ax_spec.imshow(spec_data, aspect='auto', origin='lower',\n",
        "                                 extent=[0, 100, 0, self.sample_rate/2],\n",
        "                                 cmap=colormap, vmin=-60, vmax=0)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(spec_img, ax=ax_spec, shrink=0.8)\n",
        "        cbar.set_label('Magnitude (dB)', color='white')\n",
        "        cbar.ax.yaxis.set_tick_params(color='white')\n",
        "\n",
        "        # Animation variables\n",
        "        spec_history = []\n",
        "        frame_counter = 0\n",
        "        max_history = 200  # Keep last 200 frames\n",
        "\n",
        "        def update(frame):\n",
        "            nonlocal frame_counter, spec_history\n",
        "\n",
        "            start = frame * hop_size\n",
        "            if start + window_size > len(self.audio_np):\n",
        "                return line_wave, spec_img\n",
        "\n",
        "            # Extract current audio frame\n",
        "            frame_data = self.audio_np[start:start + window_size]\n",
        "\n",
        "            # Update waveform with envelope\n",
        "            line_wave.set_ydata(frame_data)\n",
        "\n",
        "            # Compute spectrogram\n",
        "            windowed = frame_data * np.hanning(window_size)\n",
        "            fft_data = np.fft.rfft(windowed)\n",
        "            magnitude = np.abs(fft_data)[:n_bins]\n",
        "\n",
        "            # Convert to dB scale\n",
        "            magnitude_db = 20 * np.log10(np.maximum(magnitude, 1e-10))\n",
        "\n",
        "            # Add to history\n",
        "            spec_history.append(magnitude_db)\n",
        "            if len(spec_history) > max_history:\n",
        "                spec_history.pop(0)\n",
        "\n",
        "            # Update spectrogram display\n",
        "            if len(spec_history) > 1:\n",
        "                spec_array = np.column_stack(spec_history)\n",
        "                spec_img.set_array(spec_array)\n",
        "                spec_img.set_extent([0, len(spec_history), 0, self.sample_rate/2])\n",
        "\n",
        "            # Update title with progress\n",
        "            progress = (frame / n_frames) * 100\n",
        "            ax_wave.set_title(f\"🌊 Real-Time Waveform - {self.filename} ({progress:.1f}%)\",\n",
        "                            fontsize=14, color='white', pad=20)\n",
        "\n",
        "            frame_counter += 1\n",
        "            return line_wave, spec_img\n",
        "\n",
        "        # Calculate interval based on speed\n",
        "        base_interval = (hop_size / self.sample_rate) * 1000\n",
        "        interval = max(1, int(base_interval / speed_multiplier))\n",
        "\n",
        "        # Create and start animation\n",
        "        self.animation = FuncAnimation(\n",
        "            self.fig, update, frames=n_frames,\n",
        "            interval=interval, blit=False, repeat=False\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the animation and audio player\n",
        "        print(\"🎬 Starting visualization...\")\n",
        "        display(HTML(self.animation.to_jshtml()))\n",
        "\n",
        "        print(\"\\n🔊 Audio Player:\")\n",
        "        # Normalize audio for playback\n",
        "        audio_normalized = self.audio_np.astype(np.float32) / 32767.0\n",
        "        display(Audio(audio_normalized, rate=self.sample_rate, autoplay=False))\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Main method to run the complete workflow\"\"\"\n",
        "        print(\"🚀 Initializing Enhanced Audio Visualizer...\")\n",
        "\n",
        "        if self.upload_and_process_audio():\n",
        "            self.create_interactive_controls()\n",
        "            print(\"\\n✨ Setup complete! Use the controls above to customize and start the visualization.\")\n",
        "        else:\n",
        "            print(\"❌ Failed to load audio. Please try again with a supported audio file.\")\n",
        "\n",
        "# Create and run the visualizer\n",
        "visualizer = AudioVisualizer()\n",
        "visualizer.run()"
      ],
      "metadata": {
        "id": "rEh4ZT3aCj3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}